<!doctype html>
<html lang="en" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Human Emotion Detector Using EEG Signals</title>
    <meta name="theme-color" content="#f4f6fb" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Sora:wght@300;400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <link rel="stylesheet" href="styles.css" />
    <script src="model.js"></script>
    <script src="app.js" defer></script>
  </head>
  <body>
    <div class="ambient" aria-hidden="true"></div>

    <nav class="nav glass" aria-label="Primary">
      <div class="nav-brand">
        <span class="brand-logo" aria-hidden="true">DP</span>
        <span class="brand-text">Dev's Project</span>
      </div>
      <div class="nav-links">
        <a href="#input">Predict</a>
        <a href="#results">Results</a>
        <a href="#about">About</a>
        <a href="#dataset">Dataset</a>
        <a href="#theory">Theory</a>
      </div>
      <div class="nav-actions">
        <button id="theme-toggle" class="ghost" aria-label="Toggle dark mode">
          Toggle Theme
        </button>
      </div>
    </nav>

    <header class="hero" id="top">
      <canvas id="hero-canvas" aria-hidden="true"></canvas>
      <div class="hero-content glass">
        <p class="eyebrow">Dev's Project</p>
        <h1>Human Emotion Detector Using EEG Signals</h1>
        <p class="hero-subtitle">
          Enter EEG channel values to predict emotion using linear regression
          intensity and multi-class logistic regression with glassmorphism UI.
        </p>
        <div class="hero-actions">
          <a href="#input" class="btn primary">Start Predicting</a>
          <button id="autofill-hero" class="btn ghost">
            Random Example
          </button>
        </div>
        <div class="hero-meta">
          <div>
            <span>5 Subjects</span>
            <strong>155,000 Samples</strong>
          </div>
          <div>
            <span>19 Channels</span>
            <strong>Synthetic Labels</strong>
          </div>
          <div>
            <span>Models</span>
            <strong>Linear + Logistic</strong>
          </div>
        </div>
      </div>
    </header>

    <main class="container">
      <section id="input" class="section">
        <div class="section-header">
          <div>
            <h2>EEG Channel Input</h2>
            <p>Enter one sample of microvolt values across 19 channels.</p>
          </div>
          <div class="section-actions">
            <button id="autofill-btn" class="btn glass">Random Example</button>
            <button id="clear-btn" class="btn ghost">Clear All</button>
          </div>
        </div>

        <div id="alert" class="alert" hidden></div>

        <form id="eeg-form" class="glass panel" novalidate>
          <div class="input-grid" id="input-grid"></div>
          <div class="form-footer">
            <div class="tip">
              Tip: Use steady values from a single time window for best results.
            </div>
            <button id="predict-btn" class="btn primary" type="submit">
              <span class="btn-label">Predict Emotion</span>
              <span class="btn-spinner" aria-hidden="true"></span>
            </button>
          </div>
        </form>
      </section>

      <section id="results" class="section">
        <div class="section-header">
          <div>
            <h2>Prediction Results</h2>
            <p>Live inference with glassmorphism dashboards.</p>
          </div>
          <div class="section-actions">
            <button id="details-btn" class="btn glass">View Details</button>
            <button id="export-json-btn" class="btn ghost">Export JSON</button>
            <button id="export-pdf-btn" class="btn ghost">Export PDF</button>
          </div>
        </div>

        <div class="result-grid">
          <div class="glass card result-primary">
            <div class="emotion-head">
              <div id="emotion-badge" class="emotion-badge">--</div>
              <div>
                <h3 id="emotion-label" aria-live="polite">Awaiting prediction</h3>
                <p id="emotion-subtitle" aria-live="polite">
                  Enter EEG values to begin.
                </p>
              </div>
            </div>
            <canvas id="activity-canvas" aria-hidden="true"></canvas>
          </div>

          <div class="glass card">
            <h4>Confidence</h4>
            <div class="progress-ring">
              <svg width="120" height="120" viewBox="0 0 120 120">
                <circle class="ring-bg" cx="60" cy="60" r="50"></circle>
                <circle id="confidence-ring" class="ring" cx="60" cy="60" r="50"></circle>
              </svg>
              <div id="confidence-value" class="progress-text" aria-live="polite">
                0%
              </div>
            </div>
          </div>

          <div class="glass card">
            <h4>Intensity</h4>
            <div class="intensity-meter">
              <div id="intensity-fill" class="intensity-fill"></div>
            </div>
            <div id="intensity-value" class="meter-label" aria-live="polite">
              0.00 / 10
            </div>
          </div>

          <div class="glass card">
            <h4>Brain Wave</h4>
            <canvas id="result-wave" aria-hidden="true"></canvas>
          </div>
        </div>

        <div class="recent glass">
          <h4>Recent Predictions</h4>
          <div id="recent-list" class="recent-list"></div>
        </div>
      </section>

      <section id="about" class="section split">
        <div class="glass card">
          <h2>About EEG Emotion Detection</h2>
          <p>
            EEG signals capture brain activity across multiple scalp locations.
            This demo uses linear regression to estimate intensity (0-10) and
            multi-class logistic regression to predict emotions from synthetic
            labels derived from real EEG patterns.
          </p>
          <ul class="clean-list">
            <li>Transparent, interpretable regression models</li>
            <li>Designed for quick experimentation and learning</li>
            <li>Glassmorphism UI with accessible interactions</li>
          </ul>
        </div>
        <div class="glass card">
          <h2>Tips for EEG Inputs</h2>
          <ul class="clean-list">
            <li>Use consistent sampling windows for all channels</li>
            <li>Avoid mixing different sessions in one prediction</li>
            <li>Values typically fall within ±100 microvolts</li>
          </ul>
          <div class="shortcuts">
            <strong>Keyboard shortcuts</strong>
            <span>Enter: Predict</span>
            <span>Esc: Clear</span>
          </div>
        </div>
      </section>

      <section id="dataset" class="section">
        <div class="glass card">
          <h2>Dataset Info</h2>
          <div class="dataset-grid">
            <div>
              <span>Subjects</span>
              <strong>5</strong>
            </div>
            <div>
              <span>Channels</span>
              <strong>19</strong>
            </div>
            <div>
              <span>Samples</span>
              <strong>155,000</strong>
            </div>
            <div>
              <span>Labels</span>
              <strong>Synthetic (demo)</strong>
            </div>
          </div>
          <p class="muted">
            The emotion classes are simulated by partitioning intensity scores
            into six balanced groups to demonstrate multi-class logistic
            regression behavior.
          </p>
        </div>
      </section>

      <section id="theory" class="section">
        <div class="section-header">
          <div>
            <h2>Theory (EEG + Emotion Recognition)</h2>
            <p>Research-backed concepts summarized for quick learning.</p>
          </div>
        </div>

        <div class="theory-grid">
          <div class="glass card">
            <h3>EEG Basics</h3>
            <ul class="clean-list">
              <li>EEG records microvolt-level brain activity from scalp electrodes.</li>
              <li>10–20 system labels: F (frontal), C (central), T (temporal), P (parietal), O (occipital).</li>
              <li>Odd = left hemisphere, even = right hemisphere.</li>
            </ul>
          </div>

          <div class="glass card">
            <h3>Frequency Bands</h3>
            <ul class="clean-list">
              <li>Delta: &lt;4 Hz (deep sleep)</li>
              <li>Theta: 4–7 Hz (drowsy / memory)</li>
              <li>Alpha: 8–13 Hz (relaxed)</li>
              <li>Beta: 13–30 Hz (active thinking)</li>
              <li>Gamma: &gt;30 Hz (attention)</li>
            </ul>
          </div>

          <div class="glass card">
            <h3>Preprocessing</h3>
            <ul class="clean-list">
              <li>Artifact removal + bandpass filtering (e.g., 4–45 Hz).</li>
              <li>Segmentation into fixed windows (1–3 sec).</li>
              <li>Standardization or normalization for model stability.</li>
            </ul>
          </div>

          <div class="glass card">
            <h3>Feature Work</h3>
            <ul class="clean-list">
              <li>Feature extraction: band power, Differential Entropy, Hjorth, HFD.</li>
              <li>Feature selection: PCA or filter methods to reduce redundancy.</li>
              <li>Goal: compact, emotion-informative signals.</li>
            </ul>
          </div>

          <div class="glass card">
            <h3>Models</h3>
            <ul class="clean-list">
              <li>Classic ML: SVM, Logistic Regression, Random Forest, XGBoost.</li>
              <li>Deep models: CNN / RNN / GRU for spatiotemporal patterns.</li>
              <li>Regression for continuous emotion scores (VAD space).</li>
            </ul>
          </div>

          <div class="glass card">
            <h3>Evaluation</h3>
            <ul class="clean-list">
              <li>Classification: accuracy, precision, recall, F1, ROC-AUC.</li>
              <li>Regression: MSE, RMSE, MAE, R².</li>
              <li>Cross-subject validation improves realism.</li>
            </ul>
          </div>
        </div>

        <div class="glass card theory-summary">
          <h3>How This Demo Maps to Research</h3>
          <p>
            This UI focuses on explainable models: linear regression for intensity
            and logistic regression for emotion class. It mirrors the final
            inference step of larger EEG pipelines, while keeping preprocessing
            and feature engineering minimal for clarity and learning.
          </p>
          <ul class="clean-list">
            <li>Input → scale → linear model → intensity (0–10).</li>
            <li>Same input → logistic model → emotion class + confidence.</li>
            <li>Expandable to PCA, band power, DE/HFD, or CNN-based models.</li>
          </ul>
        </div>
      </section>
    </main>

    <footer class="footer glass">
      <div>
        Dev's Project • Built with linear + logistic regression only.
      </div>
      <div>Human emotion detection with EEG signals.</div>
    </footer>

    <div
      id="modal"
      class="modal"
      aria-hidden="true"
      role="dialog"
      aria-modal="true"
    >
      <div class="modal-card glass">
        <div class="modal-header">
          <h3>Prediction Details</h3>
          <button id="modal-close" class="ghost" aria-label="Close details">
            Close
          </button>
        </div>
        <div id="modal-content" class="modal-content"></div>
      </div>
    </div>

    <div id="toast-container" class="toast-container" aria-live="polite"></div>
  </body>
</html>
