{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MLDC Mapping (This Project)\n",
        "Each step below is **working here** in this notebook.\n",
        "\n",
        "1. **Problem Definition** → Emotion detection from EEG\n",
        "2. **Data Collection** → Load EEG CSVs from `features_raw.csv`\n",
        "3. **Data Processing** → Missing values + scaling\n",
        "4. **EDA** → Shape, samples, statistics\n",
        "5. **Feature Engineering** → Raw EEG channels (baseline)\n",
        "6. **Model Selection** → Linear + Logistic Regression\n",
        "7. **Deployment** → Exported to web UI in this project\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset Used (features_raw.csv)\n",
        "- 32 EEG channels per row (time samples).\n",
        "- No real labels included → we generate **synthetic** valence/arousal/dominance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Problem Definition\n",
        "We want to predict emotion dimensions from EEG: **valence**, **arousal**, **dominance**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Data Loading\n",
        "Load the EEG data file with channel columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"../features_raw.csv\")\n",
        "# Drop empty column if it exists\n",
        "if 'Unnamed: 32' in data.columns:\n",
        "    data = data.drop(columns=['Unnamed: 32'])\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) EDA (Basic Exploration)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.describe().loc[[\"mean\", \"std\"]].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Preprocessing\n",
        "- Fill missing values\n",
        "- Scale features for ML\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = data.fillna(data.mean())\n",
        "X = data.values\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Feature Selection / Creation\n",
        "We use **raw scaled EEG channels** as baseline features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Create Synthetic Valence/Arousal/Dominance Labels\n",
        "Because real emotion labels are missing, we create **pseudo-labels** using EEG patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper: scale any signal to 1–9 range\n",
        "def scale_1_9(x):\n",
        "    return (x - x.min()) / (x.max() - x.min()) * 8 + 1\n",
        "\n",
        "# Valence: frontal asymmetry (right - left)\n",
        "valence_raw = (data['F4'] + data['Fp2']) - (data['F3'] + data['Fp1'])\n",
        "\n",
        "# Arousal: overall absolute activity\n",
        "arousal_raw = data.abs().mean(axis=1)\n",
        "\n",
        "# Dominance: central + parietal activity (simple heuristic)\n",
        "dom_channels = ['C3','C4','P3','P4','Pz']\n",
        "dominance_raw = data[dom_channels].abs().mean(axis=1)\n",
        "\n",
        "# Scale to 1–9\n",
        "y_val = scale_1_9(valence_raw)\n",
        "y_ar = scale_1_9(arousal_raw)\n",
        "y_dom = scale_1_9(dominance_raw)\n",
        "\n",
        "# Binary labels (High vs Low)\n",
        "y_val_bin = (y_val > y_val.median()).astype(int)\n",
        "y_ar_bin = (y_ar > y_ar.median()).astype(int)\n",
        "y_dom_bin = (y_dom > y_dom.median()).astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Train/Test Split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Continuous splits\n",
        "X_train, X_test, yv_train, yv_test = train_test_split(X, y_val, test_size=0.2, random_state=42)\n",
        "_, _, ya_train, ya_test = train_test_split(X, y_ar, test_size=0.2, random_state=42)\n",
        "_, _, yd_train, yd_test = train_test_split(X, y_dom, test_size=0.2, random_state=42)\n",
        "\n",
        "# Binary splits\n",
        "X_train_b, X_test_b, yv_train_b, yv_test_b = train_test_split(X, y_val_bin, test_size=0.2, random_state=42)\n",
        "_, _, ya_train_b, ya_test_b = train_test_split(X, y_ar_bin, test_size=0.2, random_state=42)\n",
        "_, _, yd_train_b, yd_test_b = train_test_split(X, y_dom_bin, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Linear Regression (Intensity Scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lin = LinearRegression()\n",
        "\n",
        "# Valence\n",
        "lin.fit(X_train, yv_train)\n",
        "pred_v = lin.predict(X_test)\n",
        "print('Valence MSE:', mean_squared_error(yv_test, pred_v))\n",
        "\n",
        "# Arousal\n",
        "lin.fit(X_train, ya_train)\n",
        "pred_a = lin.predict(X_test)\n",
        "print('Arousal MSE:', mean_squared_error(ya_test, pred_a))\n",
        "\n",
        "# Dominance\n",
        "lin.fit(X_train, yd_train)\n",
        "pred_d = lin.predict(X_test)\n",
        "print('Dominance MSE:', mean_squared_error(yd_test, pred_d))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) Logistic Regression (High vs Low)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "log = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Valence High/Low\n",
        "log.fit(X_train_b, yv_train_b)\n",
        "pred_vb = log.predict(X_test_b)\n",
        "print('Valence Accuracy:', accuracy_score(yv_test_b, pred_vb))\n",
        "\n",
        "# Arousal High/Low\n",
        "log.fit(X_train_b, ya_train_b)\n",
        "pred_ab = log.predict(X_test_b)\n",
        "print('Arousal Accuracy:', accuracy_score(ya_test_b, pred_ab))\n",
        "\n",
        "# Dominance High/Low\n",
        "log.fit(X_train_b, yd_train_b)\n",
        "pred_db = log.predict(X_test_b)\n",
        "print('Dominance Accuracy:', accuracy_score(yd_test_b, pred_db))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
